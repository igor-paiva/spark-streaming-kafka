version: "3.9"

services:
  submit:
    build:
      context: ./submit
    # entrypoint:
    #   - ./spark-3.1.3-bin-hadoop3.2/bin/spark-submit
    #   - --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.3
    #   - cluster.py
    #   - ">"
    #   - test_all.txt
    volumes:
      - ./submit:/submit
      - ./spark-3.1.3-bin-hadoop3.2:/submit/spark-3.1.3-bin-hadoop3.2
    depends_on:
      # - hadoop
      - socket
      - master
      - spark-worker-1
      - spark-worker-2
      - kafka-server
    environment:
      - SPARK_LOCAL_IP=localhost
      - PYSPARK_DRIVER_PYTHON=python3
      - PYSPARK_PYTHON=python3
    networks:
      - spark-cluster

  socket:
    build:
      context: ./socket
    # entrypoint:
    #   - python3
    #   - -u
    #   - main.py
    depends_on:
      - kafka-server
    volumes:
      - ./socket:/code
      - ./kafka_2.13-3.2.1:/code/kafka_2.13-3.2.1
    networks:
      - spark-cluster

  master:
    build:
      context: ./master
    # entrypoint:
    #   - bash
    #   - spark-3.1.3-bin-hadoop3.2/sbin/start-master.sh
    ports:
      - '8080:8080'
    volumes:
      - ./spark-3.1.3-bin-hadoop3.2:/master/spark-3.1.3-bin-hadoop3.2
    networks:
      - spark-cluster

  spark-worker-1:
    build:
      context: ./worker
    # entrypoint:
    #   - bash
    #   - spark-3.1.3-bin-hadoop3.2/sbin/start-worker.sh
    #   - -m 1G
    #   - -c 1
    #   - spark://master:7077
    volumes:
      - ./spark-3.1.3-bin-hadoop3.2:/worker/spark-3.1.3-bin-hadoop3.2
    environment:
      - SPARK_MASTER_URL=spark://master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - master
    ports:
      - '8081:8081'
    networks:
      - spark-cluster

  spark-worker-2:
    build:
      context: ./worker
    # entrypoint:
    #   - bash
    #   - spark-3.1.3-bin-hadoop3.2/sbin/start-worker.sh
    #   - -m 1G
    #   - -c 1
    #   - spark://master:7077
    volumes:
      - ./spark-3.1.3-bin-hadoop3.2:/worker/spark-3.1.3-bin-hadoop3.2
    environment:
      - SPARK_MASTER_URL=spark://master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
    depends_on:
      - master
    ports:
      - '8082:8081'
    networks:
      - spark-cluster

  kafka-zookeeper:
    build:
      context: ./kafka_zookeeper
    volumes:
      - ./kafka_2.13-3.2.1:/kafka_zookeeper/kafka_2.13-3.2.1
    networks:
      - spark-cluster

  kafka-server:
    build:
      context: ./kafka_server
    depends_on:
      - kafka-zookeeper
    volumes:
      - ./kafka_2.13-3.2.1:/kafka_server/kafka_2.13-3.2.1
    networks:
      - spark-cluster

  # hadoop:
  #   image: cybermaggedon/hadoop


networks:
  spark-cluster:
    external: true
